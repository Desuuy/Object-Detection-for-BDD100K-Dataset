{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2deW8KmRNs4",
        "outputId": "c7459627-0d3a-400d-9aa2-196c00e2a816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train path exists: True\n",
            "Test path exists: True\n",
            "Val path exists: True\n",
            "\n",
            "Contents of base directory:\n",
            "['test', 'train', 'val']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Base directory where your data is located\n",
        "base_path = r'/workspace/bdd100k/BDD100k/images'\n",
        "\n",
        "# The subdirectories should be direct children of the 100k folder\n",
        "train_path = os.path.join(base_path, 'train')\n",
        "test_path = os.path.join(base_path, 'test')\n",
        "val_path = os.path.join(base_path, 'val')\n",
        "\n",
        "# First, check if the directories exist\n",
        "print(f\"Train path exists: {os.path.exists(train_path)}\")\n",
        "print(f\"Test path exists: {os.path.exists(test_path)}\")\n",
        "print(f\"Val path exists: {os.path.exists(val_path)}\")\n",
        "\n",
        "# If the above shows False, let's see what directories actually exist in base_path\n",
        "print(\"\\nContents of base directory:\")\n",
        "print(os.listdir(base_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z-4heMGSK8q",
        "outputId": "280cfd7d-943f-4f27-d648-0e06629389a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of labels in the JSON file: 69863\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "json_path = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k_labels_release\\bdd100k\\labels\\bdd100k_labels_images_train.json'\n",
        "\n",
        "with open(json_path, 'r') as f:\n",
        "    labels_data = json.load(f)\n",
        "\n",
        "num_labels = len(labels_data)\n",
        "\n",
        "print(f\"Number of labels in the JSON file: {num_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TixZ_EAgSo-H",
        "outputId": "fb224e04-d553-4207-91c7-32fb0824ad29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of images in C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\images\\100k\\train: 1160\n",
            "Number of images in C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\images\\100k\\train\\testA: 4130\n",
            "Number of images in C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\images\\100k\\train\\testB: 2748\n",
            "Number of images in C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\images\\100k\\train\\trainA: 37216\n",
            "Number of images in C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\images\\100k\\train\\trainB: 24750\n",
            "\n",
            "Total number of images: 70004\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "base_train_path =  r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\images\\100k\\train'\n",
        "\n",
        "train_subdirs = ['testA', 'testB', 'trainA', 'trainB']\n",
        "\n",
        "total_images = 0\n",
        "\n",
        "num_base_train_images = len(os.listdir(base_train_path))\n",
        "print(f\"Number of images in {base_train_path}: {num_base_train_images}\")\n",
        "total_images += num_base_train_images\n",
        "\n",
        "\n",
        "for subdir in train_subdirs:\n",
        "    subdir_path = os.path.join(base_train_path, subdir)\n",
        "    if os.path.isdir(subdir_path):\n",
        "        num_images = len(os.listdir(subdir_path))\n",
        "        print(f\"Number of images in {subdir_path}: {num_images}\")\n",
        "        total_images += num_images\n",
        "    else:\n",
        "        print(f\"Directory not found: {subdir_path}\")\n",
        "\n",
        "print(f\"\\nTotal number of images: {total_images}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiUznt79Thze",
        "outputId": "c94933bb-40bc-48cc-e538-da159b6b7a9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of images in specified directories: 70000\n",
            "Total number of entries in label JSON file: 69863\n",
            "Number of images with corresponding labels: 69863\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "base_train_path =  r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\images\\100k\\train'\n",
        "json_path = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k_labels_release\\bdd100k\\labels\\bdd100k_labels_images_train.json'\n",
        "\n",
        "train_subdirs = ['testA', 'testB', 'trainA', 'trainB']\n",
        "\n",
        "# Get list of all image filenames in the training directories and subdirectories\n",
        "image_filenames = set()\n",
        "for subdir in train_subdirs:\n",
        "    subdir_path = os.path.join(base_train_path, subdir)\n",
        "    if os.path.isdir(subdir_path):\n",
        "        for filename in os.listdir(subdir_path):\n",
        "            if filename.endswith('.jpg'): # Assuming images are JPGs\n",
        "                image_filenames.add(filename)\n",
        "\n",
        "# Add images from the base train path\n",
        "for filename in os.listdir(base_train_path):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_filenames.add(filename)\n",
        "\n",
        "\n",
        "# Load label data from JSON file\n",
        "with open(json_path, 'r') as f:\n",
        "    labels_data = json.load(f)\n",
        "\n",
        "# Get list of filenames from label data\n",
        "label_filenames = set([item['name'] for item in labels_data])\n",
        "\n",
        "# Find the number of images that have corresponding labels\n",
        "images_with_labels = image_filenames.intersection(label_filenames)\n",
        "\n",
        "print(f\"Total number of images in specified directories: {len(image_filenames)}\")\n",
        "print(f\"Total number of entries in label JSON file: {len(label_filenames)}\")\n",
        "print(f\"Number of images with corresponding labels: {len(images_with_labels)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c5ef15b"
      },
      "source": [
        "## Task\n",
        "Train a YOLOv8 model on the BDD100k dataset using the images in \"/content/bdd100k/bdd100k/images/100k/train\" and the labels in \"/content/bdd100k_labels_release/bdd100k/labels/bdd100k_labels_images_train.json\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75d4d3a9"
      },
      "source": [
        "### Install necessary libraries\n",
        "\n",
        "#### Subtask:\n",
        "Install `ultralytics` which contains the YOLOv8 implementation and other dependencies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61da3b82"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to install the `ultralytics` package. I will use pip to install the package.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "883a518e",
        "outputId": "dd179247-4370-4b37-9a30-934efbf4fe95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ultralytics in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (8.3.221)\n",
            "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (3.9.2)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.6.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (0.24.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\anhhu\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (6.0.0)\n",
            "Requirement already satisfied: polars in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (1.34.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.0.17)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\anhhu\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\anhhu\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Collecting torch>=1.8.0 (from ultralytics)\n",
            "  Using cached torch-2.9.0-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.2.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.3.0)\n",
            "Requirement already satisfied: polars-runtime-32==1.34.0 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from polars->ultralytics) (1.34.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\anhhu\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anhhu\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Using cached torch-2.9.0-cp312-cp312-win_amd64.whl (109.3 MB)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch None\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "error: uninstall-no-record-file\n",
            "\n",
            "× Cannot uninstall torch None\n",
            "╰─> The package's contents are unknown: no RECORD file was found for torch.\n",
            "\n",
            "hint: You might be able to recover from this via: pip install --force-reinstall --no-deps torch==2.6.0+cu126\n"
          ]
        }
      ],
      "source": [
        "%pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03fea66a"
      },
      "source": [
        "### Prepare the dataset\n",
        "\n",
        "#### Subtask:\n",
        "Convert the BDD100k labels to the YOLO format. This involves parsing the JSON file and creating text files for each image with bounding box information.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bcea5fa"
      },
      "source": [
        "### **Reasoning**:\n",
        "Convert the BDD100k labels to the YOLO format by parsing the JSON file and creating text files for each image with bounding box information. This involves defining paths, creating output directories, loading JSON data, iterating through images and annotations, converting bounding box coordinates to YOLO format, and writing the formatted data to text files. A category mapping is also needed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99ddea7e",
        "outputId": "b9841f8d-7662-4ce4-c26d-05ccf8e99529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DONE convert.\n",
            "Label files written: 69863  total boxes: 1286871\n",
            "Missing images in disk (but in JSON): 0\n",
            "Unknown-class annotations skipped: 0\n"
          ]
        }
      ],
      "source": [
        "import os, json, glob, re\n",
        "from collections import Counter\n",
        "\n",
        "# ===== paths =====\n",
        "IMAGES_DIR  = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\\images\\train'\n",
        "LABELS_JSON = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\\labels\\bdd100k_labels_release\\bdd100k\\labels\\bdd100k_labels_images_train.json'\n",
        "LABELS_ROOT = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\\labels\\train'\n",
        "\n",
        "os.makedirs(LABELS_ROOT, exist_ok=True)\n",
        "\n",
        "# ===== 10 lớp mục tiêu (thứ tự cố định) =====\n",
        "CLS_MAP = {\n",
        "    'person': 0,\n",
        "    'rider': 1,\n",
        "    'car': 2,\n",
        "    'bus': 3,\n",
        "    'truck': 4,\n",
        "    'bike': 5,\n",
        "    'motor': 6,\n",
        "    'traffic light': 7,\n",
        "    'traffic sign': 8,\n",
        "    'train': 9,\n",
        "}\n",
        "\n",
        "# Các biến thể → chuẩn 10 lớp\n",
        "NORMALIZE_TABLE = {\n",
        "    'person': 'person',\n",
        "    'rider': 'rider',\n",
        "    'car': 'car',\n",
        "    'bus': 'bus',\n",
        "    'truck': 'truck',\n",
        "    'bicycle': 'bike',\n",
        "    'bike': 'bike',\n",
        "    'motorcycle': 'motor',\n",
        "    'motor': 'motor',\n",
        "    'traffic light': 'traffic light',\n",
        "    'traffic sign': 'traffic sign',\n",
        "    # các biến thể hay gặp:\n",
        "    'traffic-light': 'traffic light',\n",
        "    'traffic_light': 'traffic light',\n",
        "    'trafficlight': 'traffic light',\n",
        "    'traffic-sign': 'traffic sign',\n",
        "    'traffic_sign': 'traffic sign',\n",
        "    'trafficsign': 'traffic sign',\n",
        "}\n",
        "\n",
        "def normalize_cat(raw: str) -> str | None:\n",
        "    if not raw:\n",
        "        return None\n",
        "    # ép utf-8 safe, lower, strip\n",
        "    s = raw.encode('utf-8', 'ignore').decode('utf-8').lower()\n",
        "    # thay \\xa0, tab, nhiều space về 1 space\n",
        "    s = s.replace('\\xa0', ' ')\n",
        "    s = re.sub(r'[\\t\\r\\n]+', ' ', s)\n",
        "    # unify các dấu nối\n",
        "    s = s.replace('-', ' ').replace('_', ' ')\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    # tra bảng biến thể trước\n",
        "    if s in NORMALIZE_TABLE:\n",
        "        s = NORMALIZE_TABLE[s]\n",
        "    # cuối cùng: nếu đã khớp CLS_MAP thì nhận\n",
        "    return s if s in CLS_MAP else None\n",
        "\n",
        "W, H = 1280.0, 720.0  # BDD100K mặc định\n",
        "\n",
        "# Index ảnh theo basename -> relative path\n",
        "image_index = {}\n",
        "for p in glob.glob(os.path.join(IMAGES_DIR, '**', '*.jpg'), recursive=True):\n",
        "    rel = os.path.relpath(p, IMAGES_DIR).replace('\\\\', '/')\n",
        "    image_index[os.path.basename(p)] = rel\n",
        "\n",
        "with open(LABELS_JSON, 'r', encoding='utf-8') as f:\n",
        "    items = json.load(f)\n",
        "\n",
        "miss_img = 0\n",
        "unk_cls = 0\n",
        "files_written = 0\n",
        "boxes_written = 0\n",
        "unknown_examples = Counter()\n",
        "\n",
        "for it in items:\n",
        "    name = it.get('name')\n",
        "    rel_img = image_index.get(name)\n",
        "    if rel_img is None:\n",
        "        miss_img += 1\n",
        "        continue\n",
        "\n",
        "    rel_lbl  = os.path.splitext(rel_img)[0] + '.txt'\n",
        "    out_path = os.path.join(LABELS_ROOT, rel_lbl)\n",
        "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "\n",
        "    labels = it.get('labels', [])\n",
        "    lines = []\n",
        "    for lb in labels:\n",
        "        box = lb.get('box2d')\n",
        "        raw = lb.get('category', '')\n",
        "\n",
        "        # 1) Nếu KHÔNG có box2d (vd lane, drivable area = poly2d) → bỏ qua hẳn\n",
        "        if not box:\n",
        "            continue\n",
        "\n",
        "        # 2) Có box2d ⇒ mới normalize & map\n",
        "        cat = normalize_cat(raw)\n",
        "        if not cat:\n",
        "            # chỉ cộng unknown nếu annotation có box2d nhưng cat không map\n",
        "            unknown_examples[raw] += 1\n",
        "            unk_cls += 1\n",
        "            continue\n",
        "\n",
        "        x1, x2 = float(min(box['x1'], box['x2'])), float(max(box['x1'], box['x2']))\n",
        "        y1, y2 = float(min(box['y1'], box['y2'])), float(max(box['y1'], box['y2']))\n",
        "\n",
        "        # clip biên\n",
        "        x1 = max(0.0, min(x1, W)); x2 = max(0.0, min(x2, W))\n",
        "        y1 = max(0.0, min(y1, H)); y2 = max(0.0, min(y2, H))\n",
        "        bw, bh = x2 - x1, y2 - y1\n",
        "        if bw <= 1e-6 or bh <= 1e-6:\n",
        "            continue\n",
        "\n",
        "        cx = (x1 + x2) / 2.0 / W\n",
        "        cy = (y1 + y2) / 2.0 / H\n",
        "        bw /= W; bh /= H\n",
        "\n",
        "        lines.append(f\"{CLS_MAP[cat]} {cx:.6f} {cy:.6f} {bw:.6f} {bh:.6f}\")\n",
        "\n",
        "    if lines:\n",
        "        with open(out_path, 'w', encoding='utf-8') as f:\n",
        "            f.write('\\n'.join(lines) + '\\n')\n",
        "        files_written += 1\n",
        "        boxes_written += len(lines)\n",
        "    else:\n",
        "        # xoá file rỗng cũ nếu có\n",
        "        if os.path.exists(out_path) and os.path.getsize(out_path) == 0:\n",
        "            try: os.remove(out_path)\n",
        "            except: pass\n",
        "\n",
        "print(\"DONE convert.\")\n",
        "print(\"Label files written:\", files_written, \" total boxes:\", boxes_written)\n",
        "print(\"Missing images in disk (but in JSON):\", miss_img)\n",
        "print(\"Unknown-class annotations skipped:\", unk_cls)\n",
        "\n",
        "# In top 15 nhãn lạ (nếu còn)\n",
        "if unknown_examples:\n",
        "    print(\"\\nTop unknown categories (raw) → cần bổ sung NORMALIZE nếu hợp lệ:\")\n",
        "    for k, v in unknown_examples.most_common(15):\n",
        "        print(f\"- {repr(k)}: {v}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "txt files: 69863  | non-empty: 69863\n"
          ]
        }
      ],
      "source": [
        "import os, glob\n",
        "LB_TRAIN = r\"C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\\labels\\train\"\n",
        "txts = glob.glob(os.path.join(LB_TRAIN, \"**\", \"*.txt\"), recursive=True)\n",
        "non_empty = sum(1 for p in txts if os.path.getsize(p) > 0)\n",
        "print(\"txt files:\", len(txts), \" | non-empty:\", non_empty)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21632661"
      },
      "source": [
        "##Kiểm tra dữ liệu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbLe9zMfeSyO",
        "outputId": "f4c305d5-7776-4b21-f585-326e364bd73c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images train: 70000\n",
            "Label files train: 70000\n",
            "Label files train (after): 70000\n"
          ]
        }
      ],
      "source": [
        "import os, glob\n",
        "\n",
        "IM_TRAIN = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\100k\\train'\n",
        "LB_TRAIN = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\100k\\labels\\train'\n",
        "\n",
        "# Đếm ảnh & nhãn hiện có\n",
        "imgs = glob.glob(os.path.join(IM_TRAIN, \"**\", \"*.jpg\"), recursive=True)\n",
        "txts = glob.glob(os.path.join(LB_TRAIN, \"**\", \"*.txt\"), recursive=True)\n",
        "print(\"Images train:\", len(imgs))          # ~70,000\n",
        "print(\"Label files train:\", len(txts))     # ~69,863 nếu chưa tạo rỗng\n",
        "\n",
        "# (Tuỳ chọn) tạo .txt rỗng để đủ 70,000 ảnh\n",
        "need_empty = len(imgs) - len(txts)\n",
        "if need_empty > 0:\n",
        "    made = 0\n",
        "    for img in imgs:\n",
        "        rel = os.path.relpath(img, IM_TRAIN).replace(\"\\\\\",\"/\")\n",
        "        txt = os.path.join(LB_TRAIN, os.path.splitext(rel)[0] + \".txt\")\n",
        "        if not os.path.exists(txt):\n",
        "            os.makedirs(os.path.dirname(txt), exist_ok=True)\n",
        "            open(txt, \"w\").close()\n",
        "            made += 1\n",
        "    print(\"Empty label files created:\", made)\n",
        "\n",
        "# Kiểm tra lần nữa\n",
        "txts = glob.glob(os.path.join(LB_TRAIN, \"**\", \"*.txt\"), recursive=True)\n",
        "print(\"Label files train (after):\", len(txts))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VAL convert: 10000 files written; missing images in JSON: 0\n"
          ]
        }
      ],
      "source": [
        "#Conver json to txt for Yolo\n",
        "import os, json, glob\n",
        "\n",
        "IMAGES_DIR = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\images\\100k\\val'\n",
        "LABELS_JSON = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k_labels_release\\bdd100k\\labels\\bdd100k_labels_images_val.json'\n",
        "LABELS_ROOT = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\labels\\val'\n",
        "\n",
        "os.makedirs(LABELS_ROOT, exist_ok=True)\n",
        "\n",
        "CLS_MAP = {'person':0,'rider':1,'car':2,'bus':3,'truck':4,'bike':5,'motor':6,'traffic light':7,'traffic sign':8,'train':9}\n",
        "W, H = 1280.0, 720.0\n",
        "\n",
        "# index ảnh: basename -> relative path (soi gương)\n",
        "image_index = {}\n",
        "for p in glob.glob(os.path.join(IMAGES_DIR, '**', '*.jpg'), recursive=True):\n",
        "    rel = os.path.relpath(p, IMAGES_DIR).replace('\\\\','/')\n",
        "    image_index[os.path.basename(p)] = rel\n",
        "\n",
        "with open(LABELS_JSON, 'r') as f:\n",
        "    items = json.load(f)\n",
        "\n",
        "files_written = miss_img = 0\n",
        "for it in items:\n",
        "    name = it.get('name')\n",
        "    rel_img = image_index.get(name)\n",
        "    if rel_img is None:\n",
        "        miss_img += 1\n",
        "        continue\n",
        "\n",
        "    rel_lbl = os.path.splitext(rel_img)[0] + '.txt'\n",
        "    out_path = os.path.join(LABELS_ROOT, rel_lbl)\n",
        "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "\n",
        "    lines = []\n",
        "    for lb in it.get('labels', []):\n",
        "        if 'box2d' not in lb or 'category' not in lb: continue\n",
        "        cat = lb['category']\n",
        "        if cat not in CLS_MAP: continue\n",
        "        b = lb['box2d']\n",
        "        x1, x2 = float(min(b['x1'], b['x2'])), float(max(b['x1'], b['x2']))\n",
        "        y1, y2 = float(min(b['y1'], b['y2'])), float(max(b['y1'], b['y2']))\n",
        "        # clip\n",
        "        x1=max(0,min(x1,W)); x2=max(0,min(x2,W))\n",
        "        y1=max(0,min(y1,H)); y2=max(0,min(y2,H))\n",
        "        bw, bh = x2-x1, y2-y1\n",
        "        if bw<=1e-6 or bh<=1e-6: continue\n",
        "        cx=(x1+x2)/2.0/W; cy=(y1+y2)/2.0/H; bw/=W; bh/=H\n",
        "        lines.append(f\"{CLS_MAP[cat]} {cx:.6f} {cy:.6f} {bw:.6f} {bh:.6f}\")\n",
        "\n",
        "    if lines:\n",
        "        with open(out_path,'w') as f: f.write('\\n'.join(lines))\n",
        "        files_written += 1\n",
        "\n",
        "print(\"VAL convert:\", files_written, \"files written; missing images in JSON:\", miss_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VAL images: 10000\n",
            "VAL label files: 10000\n",
            "VAL non-empty labels: 10000\n",
            "Sample img: C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\100k\\val\\b1c66a42-6f7d68ca.jpg\n",
            "Expect txt: C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\100k\\labels\\val\\b1c66a42-6f7d68ca.txt  exists: True  size: 1324\n"
          ]
        }
      ],
      "source": [
        "import os, glob\n",
        "\n",
        "IM_VAL = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\100k\\val'\n",
        "LB_VAL = r\"C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\100k\\labels\\val\"\n",
        "\n",
        "imgs = glob.glob(os.path.join(IM_VAL, \"**\", \"*.jpg\"), recursive=True)\n",
        "txts = glob.glob(os.path.join(LB_VAL, \"**\", \"*.txt\"), recursive=True)\n",
        "non_empty = [t for t in txts if os.path.getsize(t) > 0]\n",
        "\n",
        "print(\"VAL images:\", len(imgs))          # kỳ vọng ~10000\n",
        "print(\"VAL label files:\", len(txts))     # kỳ vọng ~10000 (hoặc ~số ảnh có bbox)\n",
        "print(\"VAL non-empty labels:\", len(non_empty))  # PHẢI >0\n",
        "\n",
        "\n",
        "# Lấy 1 ảnh bất kỳ và kiểm tra file nhãn “soi gương”\n",
        "sample_img = imgs[0]\n",
        "rel = os.path.relpath(sample_img, IM_VAL).replace(\"\\\\\",\"/\")\n",
        "sample_txt = os.path.join(LB_VAL, os.path.splitext(rel)[0] + \".txt\")\n",
        "print(\"Sample img:\", sample_img)\n",
        "print(\"Expect txt:\", sample_txt, \" exists:\", os.path.exists(sample_txt),\n",
        "      \" size:\", os.path.getsize(sample_txt) if os.path.exists(sample_txt) else -1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT7FfBUfqOxw"
      },
      "source": [
        "###Xóa cache và hướng đúng đường dẫn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPMEp7dKpyjR"
      },
      "source": [
        "### Dọn dữ liệu trùng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46x6Q3lxpxtl",
        "outputId": "ded9dd68-db24-4ef2-eddf-e78779b2c32e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Không thấy nhánh dư: C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\100k\\labels\\train\\train\n",
            "train txt after cleanup: 70000\n"
          ]
        }
      ],
      "source": [
        "import os, glob, shutil\n",
        "\n",
        "LB_ROOT   = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\100k\\labels\\train'\n",
        "NESTED_TR = os.path.join(LB_ROOT, 'train')  # nhánh dư thường gặp\n",
        "\n",
        "if os.path.isdir(NESTED_TR):\n",
        "    moved, replaced, removed = 0, 0, 0\n",
        "    for src in glob.glob(os.path.join(NESTED_TR, '**', '*.txt'), recursive=True):\n",
        "        rel = os.path.relpath(src, NESTED_TR)         # đường dẫn tương đối TỪ nhánh dư\n",
        "        dst = os.path.join(LB_ROOT, rel)              # đích mong muốn ở LB_ROOT\n",
        "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "\n",
        "        if os.path.exists(dst):\n",
        "            # Nếu file đích rỗng và src có nội dung -> thay thế\n",
        "            if os.path.getsize(dst) == 0 and os.path.getsize(src) > 0:\n",
        "                shutil.move(src, dst)\n",
        "                replaced += 1\n",
        "            else:\n",
        "                # Ngược lại giữ dst, xóa src dư\n",
        "                os.remove(src)\n",
        "                removed += 1\n",
        "        else:\n",
        "            shutil.move(src, dst)\n",
        "            moved += 1\n",
        "\n",
        "    # dọn thư mục rỗng\n",
        "    for root, dirs, files in os.walk(NESTED_TR, topdown=False):\n",
        "        for f in files:\n",
        "            pass\n",
        "        for d in dirs:\n",
        "            p = os.path.join(root, d)\n",
        "            if not os.listdir(p):\n",
        "                os.rmdir(p)\n",
        "    try:\n",
        "        os.rmdir(NESTED_TR)\n",
        "    except OSError:\n",
        "        pass\n",
        "\n",
        "    print(f'Done cleanup. moved={moved}, replaced={replaced}, removed_dups={removed}')\n",
        "else:\n",
        "    print('Không thấy nhánh dư:', NESTED_TR)\n",
        "\n",
        "# Đếm lại để xác nhận\n",
        "import glob\n",
        "total = len(glob.glob(os.path.join(LB_ROOT, '**', '*.txt'), recursive=True))\n",
        "print('train txt after cleanup:', total)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9aTUS1CpSwX",
        "outputId": "c1dd218d-920c-4aa0-aa9c-2032c6069d2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train txt: 70000\n",
            "val   txt: 10000\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "print(\"train txt:\", len(glob.glob(r\"C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\100k\\labels\\train\\**\\*.txt\", recursive=True))) \n",
        "print(\"val   txt:\", len(glob.glob(r\"C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\100k\\labels\\val**\\*.txt\",   recursive=True)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPfSXbc7qnWI",
        "outputId": "eb51c99b-44d8-44e2-d4c3-93804dc1f587"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train non-empty labels: 0\n",
            "Val   non-empty labels: 10000\n"
          ]
        }
      ],
      "source": [
        "import os, glob\n",
        "\n",
        "train_txts = glob.glob(r\"C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\100k\\labels\\train\\**\\*.txt\", recursive=True)\n",
        "val_txts   = glob.glob(r\"C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\100k\\labels\\val**\\*.txt\",   recursive=True)  \n",
        "\n",
        "train_non_empty = sum(1 for p in train_txts if os.path.getsize(p) > 0)\n",
        "val_non_empty   = sum(1 for p in val_txts   if os.path.getsize(p) > 0)\n",
        "\n",
        "print(\"Train non-empty labels:\", train_non_empty)\n",
        "print(\"Val   non-empty labels:\", val_non_empty)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGppAy4cqB70"
      },
      "source": [
        "###Xóa cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAnxc3LQqDs0",
        "outputId": "ff9f4205-2fc4-4492-f1bf-b33366855fcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cache cleared.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "for p in [\n",
        "    '/content/bdd100k/bdd100k/images/100k/train.cache',\n",
        "    '/content/bdd100k/bdd100k/labels/100k/train.cache',\n",
        "    '/content/bdd100k/bdd100k/images/100k/val.cache',\n",
        "    '/content/bdd100k/bdd100k/labels/100k/val.cache',\n",
        "]:\n",
        "    if os.path.exists(p):\n",
        "        os.remove(p)\n",
        "print('Cache cleared.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKNTnI4Ip3n-"
      },
      "source": [
        "###YOLO v8 Running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJnhd0P-rI3z",
        "outputId": "5bc84773-10b4-43c8-e017-5ae945a727fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLO config saved to: C:\\Users\\anhhu\\Downloads\\Company Internship\\bdd100k.yaml\n",
            "OK -> C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\n",
            "OK -> C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\\images/train\n",
            "OK -> C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\\images/val\n"
          ]
        }
      ],
      "source": [
        "import os, yaml\n",
        "\n",
        "# === 1) Khai báo đúng 10 lớp (theo mapping bạn đã convert) ===\n",
        "class_names = [\n",
        "    'person', 'rider', 'car', 'bus', 'truck',\n",
        "    'bike', 'motor', 'traffic light', 'traffic sign', 'train'\n",
        "]\n",
        "\n",
        "# === 2) Tạo data.yaml đúng với cây thư mục hiện tại ===\n",
        "ROOT = r\"C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\"   # thư mục chứa images/ và labels/\n",
        "yaml_file = r\"C:\\Users\\anhhu\\Downloads\\Company Internship\\bdd100k.yaml\"\n",
        "\n",
        "data = {\n",
        "    \"path\": ROOT.replace(\"\\\\\", \"/\"),   # dùng / cho chắc ăn trên Windows\n",
        "    \"train\": \"images/train\",\n",
        "    \"val\": \"images/val\",\n",
        "    \"test\": \"images/test\",             # có cũng được, không có YOLO sẽ bỏ qua\n",
        "    \"names\": class_names\n",
        "}\n",
        "\n",
        "os.makedirs(os.path.dirname(yaml_file), exist_ok=True)\n",
        "with open(yaml_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    yaml.dump(data, f, sort_keys=False, allow_unicode=True)\n",
        "\n",
        "print(f\"YOLO config saved to: {yaml_file}\")\n",
        "\n",
        "# (khuyến nghị) sanity check nhanh để chắc thư mục tồn tại\n",
        "for p in [ROOT, os.path.join(ROOT, \"images/train\"), os.path.join(ROOT, \"images/val\")]:\n",
        "    print(\"OK\" if os.path.exists(p) else \"MISSING\", \"->\", p)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 8.0MB/s 0.8s 0.8s<0.0s4s\n",
            "YOLOv8n summary: 129 layers, 3,157,200 parameters, 0 gradients, 8.9 GFLOPs\n",
            "Ultralytics 8.3.221  Python-3.12.3 torch-2.9.0+cpu CPU (AMD Ryzen 5 4600H with Radeon Graphics)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\anhhu\\Downloads\\Company Internship\\bdd100k.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=5, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\anhhu\\runs\\detect\\train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=10\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,012,798 parameters, 3,012,782 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.30.1 ms, read: 19.28.8 MB/s, size: 40.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\\labels\\train... 70000 images, 70000 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 70000/70000 821.6it/s 1:250.1sss\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\\labels\\train.cache\n",
            "WARNING Labels are missing or empty in C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\\labels\\train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
            "WARNING \u001b[34m\u001b[1mAutoBatch: \u001b[0mintended for CUDA devices, using default batch-size 16\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 56.110.7 MB/s, size: 50.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\\labels\\train.cache... 70000 images, 70000 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 70000/70000 27.7Mit/s 0.0s\n",
            "WARNING Labels are missing or empty in C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\\labels\\train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
            "WARNING \u001b[34m\u001b[1mtrain: \u001b[0m67.6GB RAM required to cache images with 50% safety margin but only 0.7/15.4GB available, not caching images\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.30.1 ms, read: 8.21.4 MB/s, size: 44.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\\labels\\val... 10000 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 10000/10000 409.4it/s 24.4s.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\\labels\\val.cache\n",
            "WARNING \u001b[34m\u001b[1mval: \u001b[0m9.7GB RAM required to cache images with 50% safety margin but only 0.9/15.4GB available, not caching images\n",
            "Plotting labels to C:\\Users\\anhhu\\runs\\detect\\train\\labels.jpg... \n",
            "WARNING zero-size array to reduction operation maximum which has no identity\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mC:\\Users\\anhhu\\runs\\detect\\train\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K        1/5         0G          0      128.7          0          0        640: 0% ──────────── 6/4375 0.3it/s 39.6s<3:32:330\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m num_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# nếu vẫn lỗi DataLoader, hạ xuống 0\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# === 4) Train ===\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myaml_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# đường dẫn file YAML\u001b[39;49;00m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# thử nhanh; train thật dùng 50–100\u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# train thật có thể đẩy 960–1280\u001b[39;49;00m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# auto batch theo VRAM\u001b[39;49;00m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# tái lập kết quả tốt hơn trên Windows\u001b[39;49;00m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# cache ảnh để tăng tốc (nếu đủ RAM/đĩa)\u001b[39;49;00m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclose_mosaic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# setting mặc định hợp lý cho v8\u001b[39;49;00m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# dùng backbone tiền huấn luyện\u001b[39;49;00m\n\u001b[0;32m     35\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# === 5) In thư mục lưu kết quả ===\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:800\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m--> 800\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:240\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 240\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:424\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    422\u001b[0m     loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m unwrap_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\u001b[38;5;241m.\u001b[39mloss(batch, preds)\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 424\u001b[0m     loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:138\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03mPerform forward pass of the model for either training or inference.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:338\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[1;34m(self, batch, preds)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_criterion()\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 338\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(preds, batch)\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:139\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:157\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:180\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 180\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    181\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:317\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    318\u001b[0m     y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:81\u001b[0m, in \u001b[0;36mConv.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m    Apply convolution, batch normalization and activation to input tensor.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\anhhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:543\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    533\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    534\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    542\u001b[0m     )\n\u001b[1;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import os, yaml\n",
        "import torch\n",
        "\n",
        "# === 0) Đường dẫn file YAML đã tạo ở bước trước ===\n",
        "yaml_file = r\"C:\\Users\\anhhu\\Downloads\\Company Internship\\bdd100k.yaml\"\n",
        "assert os.path.exists(yaml_file), f\"Không thấy YAML: {yaml_file}\"\n",
        "\n",
        "# === 1) Chọn weights nhất quán (v8 hoặc v11, đừng trộn) ===\n",
        "# WEIGHTS = \"yolov11n.pt\"   # nếu bạn dùng YOLOv11\n",
        "WEIGHTS = \"yolov8n.pt\"       # bạn đang dùng v8n → giữ nguyên\n",
        "\n",
        "# === 2) Khởi tạo model ===\n",
        "model = YOLO(WEIGHTS)\n",
        "model.info()\n",
        "\n",
        "# === 3) Thiết lập thiết bị và workers cho Windows ===\n",
        "# - Windows đôi khi bị lỗi DataLoader khi workers quá cao → đặt 0–2 cho chắc\n",
        "# - device=0 nếu có GPU CUDA, ngược lại chuyển \"cpu\"\n",
        "device_arg = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "num_workers = 2  # nếu vẫn lỗi DataLoader, hạ xuống 0\n",
        "\n",
        "# === 4) Train ===\n",
        "results = model.train(\n",
        "    data=yaml_file,     # đường dẫn file YAML\n",
        "    epochs=5,           # thử nhanh; train thật dùng 50–100\n",
        "    imgsz=640,          # train thật có thể đẩy 960–1280\n",
        "    batch=-1,           # auto batch theo VRAM\n",
        "    workers=num_workers,\n",
        "    device=device_arg,\n",
        "    deterministic=True, # tái lập kết quả tốt hơn trên Windows\n",
        "    cache=True,         # cache ảnh để tăng tốc (nếu đủ RAM/đĩa)\n",
        "    close_mosaic=10,    # setting mặc định hợp lý cho v8\n",
        "    pretrained=True     # dùng backbone tiền huấn luyện\n",
        ")\n",
        "\n",
        "# === 5) In thư mục lưu kết quả ===\n",
        "try:\n",
        "    print(\"Save dir:\", results.save_dir)\n",
        "except Exception:\n",
        "    try:\n",
        "        print(\"Save dir:\", model.trainer.save_dir)\n",
        "    except Exception:\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ILb6WZPux4P"
      },
      "source": [
        "### Đánh giá kết quả"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
