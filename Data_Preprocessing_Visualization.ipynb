{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2deW8KmRNs4",
        "outputId": "c7459627-0d3a-400d-9aa2-196c00e2a816"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Base directory where your data is located\n",
        "base_path = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\images\\100k'\n",
        "\n",
        "# The subdirectories should be direct children of the 100k folder\n",
        "train_path = os.path.join(base_path, 'train')\n",
        "test_path = os.path.join(base_path, 'test')\n",
        "val_path = os.path.join(base_path, 'val')\n",
        "\n",
        "# First, check if the directories exist\n",
        "print(f\"Train path exists: {os.path.exists(train_path)}\")\n",
        "print(f\"Test path exists: {os.path.exists(test_path)}\")\n",
        "print(f\"Val path exists: {os.path.exists(val_path)}\")\n",
        "\n",
        "# If the above shows False, let's see what directories actually exist in base_path\n",
        "print(\"\\nContents of base directory:\")\n",
        "print(os.listdir(base_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z-4heMGSK8q",
        "outputId": "280cfd7d-943f-4f27-d648-0e06629389a9"
      },
      "outputs": [],
      "source": [
        "# Count number of labels in the JSON file\n",
        "import json\n",
        "\n",
        "json_path = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k_labels_release\\bdd100k\\labels\\bdd100k_labels_images_train.json'\n",
        "\n",
        "with open(json_path, 'r') as f:\n",
        "    labels_data = json.load(f)\n",
        "\n",
        "num_labels = len(labels_data)\n",
        "\n",
        "print(f\"Number of labels in the JSON file: {num_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TixZ_EAgSo-H",
        "outputId": "fb224e04-d553-4207-91c7-32fb0824ad29"
      },
      "outputs": [],
      "source": [
        "# Count number of images in the train directory\n",
        "import os\n",
        "\n",
        "base_train_path =  r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\images\\100k\\train'\n",
        "\n",
        "train_subdirs = ['testA', 'testB', 'trainA', 'trainB']\n",
        "\n",
        "total_images = 0\n",
        "\n",
        "num_base_train_images = len(os.listdir(base_train_path))\n",
        "print(f\"Number of images in {base_train_path}: {num_base_train_images}\")\n",
        "total_images += num_base_train_images\n",
        "\n",
        "\n",
        "for subdir in train_subdirs:\n",
        "    subdir_path = os.path.join(base_train_path, subdir)\n",
        "    if os.path.isdir(subdir_path):\n",
        "        num_images = len(os.listdir(subdir_path))\n",
        "        print(f\"Number of images in {subdir_path}: {num_images}\")\n",
        "        total_images += num_images\n",
        "    else:\n",
        "        print(f\"Directory not found: {subdir_path}\")\n",
        "\n",
        "print(f\"\\nTotal number of images: {total_images}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiUznt79Thze",
        "outputId": "c94933bb-40bc-48cc-e538-da159b6b7a9e"
      },
      "outputs": [],
      "source": [
        "# Total label in the JSON file and number of empty label files\n",
        "import os\n",
        "import json\n",
        "\n",
        "base_train_path =  r'C:\\Users\\Company Internship\\archive\\bdd100k\\bdd100k\\images\\100k\\train'\n",
        "json_path = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k_labels_release\\bdd100k\\labels\\bdd100k_labels_images_train.json'\n",
        "\n",
        "train_subdirs = ['testA', 'testB', 'trainA', 'trainB']\n",
        "\n",
        "# Get list of all image filenames in the training directories and subdirectories\n",
        "image_filenames = set()\n",
        "for subdir in train_subdirs:\n",
        "    subdir_path = os.path.join(base_train_path, subdir)\n",
        "    if os.path.isdir(subdir_path):\n",
        "        for filename in os.listdir(subdir_path):\n",
        "            if filename.endswith('.jpg'): # Assuming images are JPGs\n",
        "                image_filenames.add(filename)\n",
        "\n",
        "# Add images from the base train path\n",
        "for filename in os.listdir(base_train_path):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_filenames.add(filename)\n",
        "\n",
        "\n",
        "# Load label data from JSON file\n",
        "with open(json_path, 'r') as f:\n",
        "    labels_data = json.load(f)\n",
        "\n",
        "# Get list of filenames from label data\n",
        "label_filenames = set([item['name'] for item in labels_data])\n",
        "\n",
        "# Find the number of images that have corresponding labels\n",
        "images_with_labels = image_filenames.intersection(label_filenames)\n",
        "\n",
        "print(f\"Total number of images in specified directories: {len(image_filenames)}\")\n",
        "print(f\"Total number of entries in label JSON file: {len(label_filenames)}\")\n",
        "print(f\"Number of images with corresponding labels: {len(images_with_labels)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03fea66a"
      },
      "source": [
        "### 2. Prepare the dataset :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bcea5fa"
      },
      "source": [
        "#### Reasoning:\n",
        "Convert the BDD100k labels to the YOLO format by parsing the JSON file and creating text files for each image with bounding box information. This involves defining paths, creating output directories, loading JSON data, iterating through images and annotations, converting bounding box coordinates to YOLO format, and writing the formatted data to text files. A category mapping is also needed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99ddea7e",
        "outputId": "b9841f8d-7662-4ce4-c26d-05ccf8e99529"
      },
      "outputs": [],
      "source": [
        "#### Subtask: Convert the BDD100k labels to the YOLO format. This involves parsing the JSON file and creating text files for each image with bounding box information.\n",
        "\n",
        "import os, json, glob, re\n",
        "from collections import Counter\n",
        "# ===== paths =====\n",
        "IMAGES_DIR  = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\\images\\train'\n",
        "LABELS_JSON = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\\labels\\bdd100k_labels_release\\bdd100k\\labels\\bdd100k_labels_images_train.json'\n",
        "LABELS_ROOT = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\\labels\\train'\n",
        "\n",
        "os.makedirs(LABELS_ROOT, exist_ok=True)\n",
        "\n",
        "# ===== 10 lớp mục tiêu (thứ tự cố định) =====\n",
        "CLS_MAP = {\n",
        "    'person': 0,\n",
        "    'rider': 1,\n",
        "    'car': 2,\n",
        "    'bus': 3,\n",
        "    'truck': 4,\n",
        "    'bike': 5,\n",
        "    'motor': 6,\n",
        "    'traffic light': 7,\n",
        "    'traffic sign': 8,\n",
        "    'train': 9,\n",
        "}\n",
        "\n",
        "# Các biến thể → chuẩn 10 lớp\n",
        "NORMALIZE_TABLE = {\n",
        "    'person': 'person',\n",
        "    'rider': 'rider',\n",
        "    'car': 'car',\n",
        "    'bus': 'bus',\n",
        "    'truck': 'truck',\n",
        "    'bicycle': 'bike',\n",
        "    'bike': 'bike',\n",
        "    'motorcycle': 'motor',\n",
        "    'motor': 'motor',\n",
        "    'traffic light': 'traffic light',\n",
        "    'traffic sign': 'traffic sign',\n",
        "    # các biến thể hay gặp:\n",
        "    'traffic-light': 'traffic light',\n",
        "    'traffic_light': 'traffic light',\n",
        "    'trafficlight': 'traffic light',\n",
        "    'traffic-sign': 'traffic sign',\n",
        "    'traffic_sign': 'traffic sign',\n",
        "    'trafficsign': 'traffic sign',\n",
        "}\n",
        "\n",
        "def normalize_cat(raw: str) -> str | None:\n",
        "    if not raw:\n",
        "        return None\n",
        "    # ép utf-8 safe, lower, strip\n",
        "    s = raw.encode('utf-8', 'ignore').decode('utf-8').lower()\n",
        "    # thay \\xa0, tab, nhiều space về 1 space\n",
        "    s = s.replace('\\xa0', ' ')\n",
        "    s = re.sub(r'[\\t\\r\\n]+', ' ', s)\n",
        "    # unify các dấu nối\n",
        "    s = s.replace('-', ' ').replace('_', ' ')\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    # tra bảng biến thể trước\n",
        "    if s in NORMALIZE_TABLE:\n",
        "        s = NORMALIZE_TABLE[s]\n",
        "    # cuối cùng: nếu đã khớp CLS_MAP thì nhận\n",
        "    return s if s in CLS_MAP else None\n",
        "\n",
        "W, H = 1280.0, 720.0  # BDD100K mặc định\n",
        "\n",
        "# Index ảnh theo basename -> relative path\n",
        "image_index = {}\n",
        "for p in glob.glob(os.path.join(IMAGES_DIR, '**', '*.jpg'), recursive=True):\n",
        "    rel = os.path.relpath(p, IMAGES_DIR).replace('\\\\', '/')\n",
        "    image_index[os.path.basename(p)] = rel\n",
        "\n",
        "with open(LABELS_JSON, 'r', encoding='utf-8') as f:\n",
        "    items = json.load(f)\n",
        "\n",
        "miss_img = 0\n",
        "unk_cls = 0\n",
        "files_written = 0\n",
        "boxes_written = 0\n",
        "unknown_examples = Counter()\n",
        "\n",
        "for it in items:\n",
        "    name = it.get('name')\n",
        "    rel_img = image_index.get(name)\n",
        "    if rel_img is None:\n",
        "        miss_img += 1\n",
        "        continue\n",
        "\n",
        "    rel_lbl  = os.path.splitext(rel_img)[0] + '.txt'\n",
        "    out_path = os.path.join(LABELS_ROOT, rel_lbl)\n",
        "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "\n",
        "    labels = it.get('labels', [])\n",
        "    lines = []\n",
        "    for lb in labels:\n",
        "        box = lb.get('box2d')\n",
        "        raw = lb.get('category', '')\n",
        "\n",
        "        # 1) Nếu KHÔNG có box2d (vd lane, drivable area = poly2d) → bỏ qua hẳn\n",
        "        if not box:\n",
        "            continue\n",
        "\n",
        "        # 2) Có box2d ⇒ mới normalize & map\n",
        "        cat = normalize_cat(raw)\n",
        "        if not cat:\n",
        "            # chỉ cộng unknown nếu annotation có box2d nhưng cat không map\n",
        "            unknown_examples[raw] += 1\n",
        "            unk_cls += 1\n",
        "            continue\n",
        "\n",
        "        x1, x2 = float(min(box['x1'], box['x2'])), float(max(box['x1'], box['x2']))\n",
        "        y1, y2 = float(min(box['y1'], box['y2'])), float(max(box['y1'], box['y2']))\n",
        "\n",
        "        # clip biên\n",
        "        x1 = max(0.0, min(x1, W)); x2 = max(0.0, min(x2, W))\n",
        "        y1 = max(0.0, min(y1, H)); y2 = max(0.0, min(y2, H))\n",
        "        bw, bh = x2 - x1, y2 - y1\n",
        "        if bw <= 1e-6 or bh <= 1e-6:\n",
        "            continue\n",
        "\n",
        "        cx = (x1 + x2) / 2.0 / W\n",
        "        cy = (y1 + y2) / 2.0 / H\n",
        "        bw /= W; bh /= H\n",
        "\n",
        "        lines.append(f\"{CLS_MAP[cat]} {cx:.6f} {cy:.6f} {bw:.6f} {bh:.6f}\")\n",
        "\n",
        "    if lines:\n",
        "        with open(out_path, 'w', encoding='utf-8') as f:\n",
        "            f.write('\\n'.join(lines) + '\\n')\n",
        "        files_written += 1\n",
        "        boxes_written += len(lines)\n",
        "    else:\n",
        "        # xoá file rỗng cũ nếu có\n",
        "        if os.path.exists(out_path) and os.path.getsize(out_path) == 0:\n",
        "            try: os.remove(out_path)\n",
        "            except: pass\n",
        "\n",
        "print(\"DONE convert.\")\n",
        "print(\"Label files written:\", files_written, \" total boxes:\", boxes_written)\n",
        "print(\"Missing images in disk (but in JSON):\", miss_img)\n",
        "print(\"Unknown-class annotations skipped:\", unk_cls)\n",
        "\n",
        "# In top 15 nhãn lạ (nếu còn)\n",
        "if unknown_examples:\n",
        "    print(\"\\nTop unknown categories (raw) → cần bổ sung NORMALIZE nếu hợp lệ:\")\n",
        "    for k, v in unknown_examples.most_common(15):\n",
        "        print(f\"- {repr(k)}: {v}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, glob\n",
        "LB_TRAIN = r\"C:\\Users\\anhhu\\Downloads\\Company Internship\\BDD100k\\labels\\train\"\n",
        "txts = glob.glob(os.path.join(LB_TRAIN, \"**\", \"*.txt\"), recursive=True)\n",
        "non_empty = sum(1 for p in txts if os.path.getsize(p) > 0)\n",
        "print(\"txt files:\", len(txts), \" | non-empty:\", non_empty)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21632661"
      },
      "source": [
        "#### Kiểm tra dữ liệu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbLe9zMfeSyO",
        "outputId": "f4c305d5-7776-4b21-f585-326e364bd73c"
      },
      "outputs": [],
      "source": [
        "import os, glob\n",
        "\n",
        "IM_TRAIN = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\100k\\train'\n",
        "LB_TRAIN = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\100k\\labels\\train'\n",
        "\n",
        "# Đếm ảnh & nhãn hiện có\n",
        "imgs = glob.glob(os.path.join(IM_TRAIN, \"**\", \"*.jpg\"), recursive=True)\n",
        "txts = glob.glob(os.path.join(LB_TRAIN, \"**\", \"*.txt\"), recursive=True)\n",
        "print(\"Images train:\", len(imgs))          # ~70,000\n",
        "print(\"Label files train:\", len(txts))     # ~69,863 nếu chưa tạo rỗng\n",
        "\n",
        "# (Tuỳ chọn) tạo .txt rỗng để đủ 70,000 ảnh\n",
        "need_empty = len(imgs) - len(txts)\n",
        "if need_empty > 0:\n",
        "    made = 0\n",
        "    for img in imgs:\n",
        "        rel = os.path.relpath(img, IM_TRAIN).replace(\"\\\\\",\"/\")\n",
        "        txt = os.path.join(LB_TRAIN, os.path.splitext(rel)[0] + \".txt\")\n",
        "        if not os.path.exists(txt):\n",
        "            os.makedirs(os.path.dirname(txt), exist_ok=True)\n",
        "            open(txt, \"w\").close()\n",
        "            made += 1\n",
        "    print(\"Empty label files created:\", made)\n",
        "\n",
        "# Kiểm tra lần nữa\n",
        "txts = glob.glob(os.path.join(LB_TRAIN, \"**\", \"*.txt\"), recursive=True)\n",
        "print(\"Label files train (after):\", len(txts))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Conver json to txt for Yolo\n",
        "import os, json, glob\n",
        "\n",
        "IMAGES_DIR = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\images\\100k\\val'\n",
        "LABELS_JSON = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k_labels_release\\bdd100k\\labels\\bdd100k_labels_images_val.json'\n",
        "LABELS_ROOT = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\labels\\val'\n",
        "\n",
        "os.makedirs(LABELS_ROOT, exist_ok=True)\n",
        "\n",
        "CLS_MAP = {'person':0,'rider':1,'car':2,'bus':3,'truck':4,'bike':5,'motor':6,'traffic light':7,'traffic sign':8,'train':9}\n",
        "W, H = 1280.0, 720.0\n",
        "\n",
        "# index ảnh: basename -> relative path (soi gương)\n",
        "image_index = {}\n",
        "for p in glob.glob(os.path.join(IMAGES_DIR, '**', '*.jpg'), recursive=True):\n",
        "    rel = os.path.relpath(p, IMAGES_DIR).replace('\\\\','/')\n",
        "    image_index[os.path.basename(p)] = rel\n",
        "\n",
        "with open(LABELS_JSON, 'r') as f:\n",
        "    items = json.load(f)\n",
        "\n",
        "files_written = miss_img = 0\n",
        "for it in items:\n",
        "    name = it.get('name')\n",
        "    rel_img = image_index.get(name)\n",
        "    if rel_img is None:\n",
        "        miss_img += 1\n",
        "        continue\n",
        "\n",
        "    rel_lbl = os.path.splitext(rel_img)[0] + '.txt'\n",
        "    out_path = os.path.join(LABELS_ROOT, rel_lbl)\n",
        "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "\n",
        "    lines = []\n",
        "    for lb in it.get('labels', []):\n",
        "        if 'box2d' not in lb or 'category' not in lb: continue\n",
        "        cat = lb['category']\n",
        "        if cat not in CLS_MAP: continue\n",
        "        b = lb['box2d']\n",
        "        x1, x2 = float(min(b['x1'], b['x2'])), float(max(b['x1'], b['x2']))\n",
        "        y1, y2 = float(min(b['y1'], b['y2'])), float(max(b['y1'], b['y2']))\n",
        "        # clip\n",
        "        x1=max(0,min(x1,W)); x2=max(0,min(x2,W))\n",
        "        y1=max(0,min(y1,H)); y2=max(0,min(y2,H))\n",
        "        bw, bh = x2-x1, y2-y1\n",
        "        if bw<=1e-6 or bh<=1e-6: continue\n",
        "        cx=(x1+x2)/2.0/W; cy=(y1+y2)/2.0/H; bw/=W; bh/=H\n",
        "        lines.append(f\"{CLS_MAP[cat]} {cx:.6f} {cy:.6f} {bw:.6f} {bh:.6f}\")\n",
        "\n",
        "    if lines:\n",
        "        with open(out_path,'w') as f: f.write('\\n'.join(lines))\n",
        "        files_written += 1\n",
        "\n",
        "print(\"VAL convert:\", files_written, \"files written; missing images in JSON:\", miss_img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, glob\n",
        "\n",
        "IM_VAL = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\100k\\val'\n",
        "LB_VAL = r\"C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\100k\\labels\\val\"\n",
        "\n",
        "imgs = glob.glob(os.path.join(IM_VAL, \"**\", \"*.jpg\"), recursive=True)\n",
        "txts = glob.glob(os.path.join(LB_VAL, \"**\", \"*.txt\"), recursive=True)\n",
        "non_empty = [t for t in txts if os.path.getsize(t) > 0]\n",
        "\n",
        "print(\"VAL images:\", len(imgs))          # kỳ vọng ~10000\n",
        "print(\"VAL label files:\", len(txts))     # kỳ vọng ~10000 (hoặc ~số ảnh có bbox)\n",
        "print(\"VAL non-empty labels:\", len(non_empty))  # PHẢI >0\n",
        "\n",
        "\n",
        "# Lấy 1 ảnh bất kỳ và kiểm tra file nhãn “soi gương”\n",
        "sample_img = imgs[0]\n",
        "rel = os.path.relpath(sample_img, IM_VAL).replace(\"\\\\\",\"/\")\n",
        "sample_txt = os.path.join(LB_VAL, os.path.splitext(rel)[0] + \".txt\")\n",
        "print(\"Sample img:\", sample_img)\n",
        "print(\"Expect txt:\", sample_txt, \" exists:\", os.path.exists(sample_txt),\n",
        "      \" size:\", os.path.getsize(sample_txt) if os.path.exists(sample_txt) else -1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPMEp7dKpyjR"
      },
      "source": [
        "#### Dọn dữ liệu trùng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46x6Q3lxpxtl",
        "outputId": "ded9dd68-db24-4ef2-eddf-e78779b2c32e"
      },
      "outputs": [],
      "source": [
        "import os, glob, shutil\n",
        "\n",
        "LB_ROOT   = r'C:\\Users\\anhhu\\Downloads\\Company Internship\\archive\\bdd100k\\bdd100k\\100k\\labels\\train'\n",
        "NESTED_TR = os.path.join(LB_ROOT, 'train')  # nhánh dư thường gặp\n",
        "\n",
        "if os.path.isdir(NESTED_TR):\n",
        "    moved, replaced, removed = 0, 0, 0\n",
        "    for src in glob.glob(os.path.join(NESTED_TR, '**', '*.txt'), recursive=True):\n",
        "        rel = os.path.relpath(src, NESTED_TR)         # đường dẫn tương đối TỪ nhánh dư\n",
        "        dst = os.path.join(LB_ROOT, rel)              # đích mong muốn ở LB_ROOT\n",
        "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "\n",
        "        if os.path.exists(dst):\n",
        "            # Nếu file đích rỗng và src có nội dung -> thay thế\n",
        "            if os.path.getsize(dst) == 0 and os.path.getsize(src) > 0:\n",
        "                shutil.move(src, dst)\n",
        "                replaced += 1\n",
        "            else:\n",
        "                # Ngược lại giữ dst, xóa src dư\n",
        "                os.remove(src)\n",
        "                removed += 1\n",
        "        else:\n",
        "            shutil.move(src, dst)\n",
        "            moved += 1\n",
        "\n",
        "    # dọn thư mục rỗng\n",
        "    for root, dirs, files in os.walk(NESTED_TR, topdown=False):\n",
        "        for f in files:\n",
        "            pass\n",
        "        for d in dirs:\n",
        "            p = os.path.join(root, d)\n",
        "            if not os.listdir(p):\n",
        "                os.rmdir(p)\n",
        "    try:\n",
        "        os.rmdir(NESTED_TR)\n",
        "    except OSError:\n",
        "        pass\n",
        "\n",
        "    print(f'Done cleanup. moved={moved}, replaced={replaced}, removed_dups={removed}')\n",
        "else:\n",
        "    print('Không thấy nhánh dư:', NESTED_TR)\n",
        "\n",
        "# Đếm lại để xác nhận\n",
        "import glob\n",
        "total = len(glob.glob(os.path.join(LB_ROOT, '**', '*.txt'), recursive=True))\n",
        "print('train txt after cleanup:', total)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, glob\n",
        "\n",
        "IM_VAL = r'/workspace/bdd100k/BDD100k/images/val'\n",
        "LB_VAL = r'/workspace/bdd100k/BDD100k/labels/val'\n",
        "\n",
        "imgs = glob.glob(os.path.join(IM_VAL, \"**\", \"*.jpg\"), recursive=True)\n",
        "txts = glob.glob(os.path.join(LB_VAL, \"**\", \"*.txt\"), recursive=True)\n",
        "non_empty = [t for t in txts if os.path.getsize(t) > 0]\n",
        "\n",
        "print(\"VAL images:\", len(imgs))          # kỳ vọng ~10000\n",
        "print(\"VAL label files:\", len(txts))     # kỳ vọng ~10000 (hoặc ~số ảnh có bbox)\n",
        "print(\"VAL non-empty labels:\", len(non_empty))  # PHẢI >0\n",
        "\n",
        "\n",
        "# Lấy 1 ảnh bất kỳ và kiểm tra file nhãn “soi gương”\n",
        "sample_img = imgs[0]\n",
        "rel = os.path.relpath(sample_img, IM_VAL).replace(\"\\\\\",\"/\")\n",
        "sample_txt = os.path.join(LB_VAL, os.path.splitext(rel)[0] + \".txt\")\n",
        "print(\"Sample img:\", sample_img)\n",
        "print(\"Expect txt:\", sample_txt, \" exists:\", os.path.exists(sample_txt),\n",
        "      \" size:\", os.path.getsize(sample_txt) if os.path.exists(sample_txt) else -1)\n",
        "\n",
        "print(\"train txt:\", len(glob.glob(r\"/workspace/bdd100k/BDD100k/labels/train/**/*.txt\", recursive=True))) \n",
        "print(\"val   txt:\", len(glob.glob(r\"/workspace/bdd100k/BDD100k/labels/val/**/*.txt\",   recursive=True)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGppAy4cqB70"
      },
      "source": [
        "#### Xóa cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAnxc3LQqDs0",
        "outputId": "ff9f4205-2fc4-4492-f1bf-b33366855fcb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "for p in [\n",
        "    '/content/bdd100k/bdd100k/images/100k/train.cache',\n",
        "    '/content/bdd100k/bdd100k/labels/100k/train.cache',\n",
        "    '/content/bdd100k/bdd100k/images/100k/val.cache',\n",
        "    '/content/bdd100k/bdd100k/labels/100k/val.cache',\n",
        "]:\n",
        "    if os.path.exists(p):\n",
        "        os.remove(p)\n",
        "print('Cache cleared.')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
